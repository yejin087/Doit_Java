{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [['green', 3, 'apple'],\n",
    "                 ['yellow', 3, 'apple'],\n",
    "                 ['red', 3, 'grape'],\n",
    "                 ['red', 3, 'grape'],\n",
    "                 ['yellow', 3, 'lemon']]\n",
    "\n",
    "\n",
    "def fruit_counts(training_data):\n",
    "    counts = {}\n",
    "    for f in training_data:\n",
    "        color = f[0]\n",
    "        if color not in counts:\n",
    "            counts[color] =0\n",
    "        counts[color] +=1    \n",
    "    return counts\n",
    "  \n",
    "result = fruit_counts(training_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1    2    3    4\n",
      "2015  500  450  520  610\n",
      "2016  700  750  720  710\n",
      "2017  800  850  820  810\n",
      "2018  900  950  920  910\n",
      "2019  100  150  120  110\n",
      "2020  200  250  220  210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'2015': [500,450,520,610],\n",
    " '2016':[700,750,720,710],\n",
    " '2017':[800,850,820,810],\n",
    " '2018':[900,950,920,910],\n",
    "  '2019':[100,150,120,110],\n",
    "   '2020':[200,250,220,210]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df.set_axis(['1','2','3','4'] ,axis=1, inplace=True)\n",
    "df.to_csv('./csv/dic_to_csv.csv', encoding=\"utf-8-sig\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹에서 스크래핑\n",
    "### BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html><body>\n",
      "<h1 id=\"title\">hello world</h1>\n",
      "<p id=\"body\">web page</p>\n",
      "<p>scraping</p>\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "    <html><body>\n",
    "    <h1 id='title'>hello world</h1>\n",
    "    <p id='body'>web page</p>\n",
    "    <p>scraping</p>\n",
    "    </body></html>\"\"\"\n",
    "    \n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>hello world</h1>\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(soup.html.body.h1)\n",
    "print(soup.html.body.h1.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>web page</p>\n"
     ]
    }
   ],
   "source": [
    "p = soup.html.body.p\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>scraping</p>\n"
     ]
    }
   ],
   "source": [
    "p1 = p.next_sibling.next_sibling\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">hello world</h1>\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(id='title')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web page\n"
     ]
    }
   ],
   "source": [
    "body = soup.find(id=\"body\").string\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\n",
      "<http.client.HTTPResponse object at 0x000001F0B503A850>\n",
      "기상청 육상 중기예보\n",
      "○ (강수) 23일(토) 오후부터 24일(일) 오전 사이 전국에 비가 오겠고, 강원영동은 24일(일) 오후까지 이어지는 곳이 있겠습니다. 27일(수)은 수도권과 강원영서에 비가 오겠습니다. <br />○ (기온) 이번 예보기간 아침 기온은 22~26도로 어제(19일, 아침최저기온 20~24도)보다 조금 높겠고, 낮 기온은 28~34도로 어제(낮최고기온 27~34도)와 비슷하겠습니다. <br />○ (주말전망) 23일(토) 오후부터 24일(일) 오전 사이 전국에 비가 오겠고, 강원영동은 24일(일) 오후까지 이어지는 곳이 있겠습니다.<br />              아침 기온은 22~24도, 낮 기온은 28~32도가 되겠습니다.<br /><br />* 이번 예보기간 북태평양고기압의 발달 여부와 정체전선의 위치에 따라 강수 구역이 변동될 수 있으며, 정체전선의 영향권에서 벗어난 지역에도 대기 불안정으로 소나기가 내릴 가능성이 있겠으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "print(url)\n",
    "res = req.urlopen(url)\n",
    "print(res)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "title = soup.find('title').string\n",
    "print(title)\n",
    "\n",
    "wf = soup.find('wf').string\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위키 도서\n",
      "위키 도서\n",
      "위키 도서\n",
      "위키 도서\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\" \n",
    "    <html><body>\n",
    "    <div id='meigen'>\n",
    "    <h1 id=\"title\">위키 도서</h1>\n",
    "    <ul class='items'>\n",
    "        <li>유니티 게임</li>\n",
    "        <li>스위프트</li>\n",
    "        <li>웹 디자인</li>\n",
    "    </ul>\n",
    "    </div>\n",
    "    </body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "h1 = soup.find('h1').string\n",
    "print(h1)\n",
    "\n",
    "h1_1 = soup.select_one('h1').string\n",
    "print(h1_1)\n",
    "\n",
    "h1_2 = soup.select_one('div>h1').string\n",
    "print(h1_2)\n",
    "\n",
    "h1_3 = soup.select_one('div#meigen > h1').string\n",
    "print(h1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>유니티 게임</li>, <li>스위프트</li>, <li>웹 디자인</li>]\n",
      "유니티 게임\n",
      "스위프트\n",
      "웹 디자인\n"
     ]
    }
   ],
   "source": [
    "li_list = soup.select('div#meigen > ul.items > li ')\n",
    "print(li_list)\n",
    "\n",
    "for li in li_list:\n",
    "    print(li.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>유니티 게임</li>, <li>스위프트</li>, <li>웹 디자인</li>]\n"
     ]
    }
   ],
   "source": [
    "lis = soup.select('li')\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"blind\">상승</span>]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "\n",
    "subtrac = soup.select('#exchangeList > li.on > a.head.usd > div > span:nth-child(4n)')\n",
    "print(subtrac)\n",
    "\n",
    "# 리스트로 반환된다\n",
    "sub2 = soup.select(\"span\")\n",
    "# print(sub2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘과 바람과 별과 시\n",
      "증보판\n",
      "서시\n",
      "자화상\n",
      "소년\n",
      "눈 오는 지도\n",
      "돌아와 보는 밤\n",
      "병원\n",
      "새로운 길\n",
      "간판 없는 거리\n",
      "태초의 아침\n",
      "또 태초의 아침\n",
      "새벽이 올 때까지\n",
      "무서운 시간\n",
      "십자가\n",
      "바람이 불어\n",
      "슬픈 족속\n",
      "눈감고 간다\n",
      "또 다른 고향\n",
      "길\n",
      "별 헤는 밤\n",
      "흰 그림자\n",
      "사랑스런 추억\n",
      "흐르는 거리\n",
      "쉽게 씌어진 시\n",
      "봄\n",
      "참회록\n",
      "간(肝)\n",
      "위로\n",
      "팔복\n",
      "못자는밤\n",
      "달같이\n",
      "고추밭\n",
      "아우의 인상화\n",
      "사랑의 전당\n",
      "이적\n",
      "비오는 밤\n",
      "산골물\n",
      "유언\n",
      "창\n",
      "바다\n",
      "비로봉\n",
      "산협의 오후\n",
      "명상\n",
      "소낙비\n",
      "한난계\n",
      "풍경\n",
      "달밤\n",
      "장\n",
      "밤\n",
      "황혼이 바다가 되어\n",
      "아침\n",
      "빨래\n",
      "꿈은 깨어지고\n",
      "산림\n",
      "이런날\n",
      "산상\n",
      "양지쪽\n",
      "닭\n",
      "가슴 1\n",
      "가슴 2\n",
      "비둘기\n",
      "황혼\n",
      "남쪽 하늘\n",
      "창공\n",
      "거리에서\n",
      "삶과 죽음\n",
      "초한대\n",
      "산울림\n",
      "해바라기 얼굴\n",
      "귀뚜라미와 나와\n",
      "애기의 새벽\n",
      "햇빛·바람\n",
      "반디불\n",
      "둘 다\n",
      "거짓부리\n",
      "눈\n",
      "참새\n",
      "버선본\n",
      "편지\n",
      "봄\n",
      "무얼 먹구 사나\n",
      "굴뚝\n",
      "햇비\n",
      "빗자루\n",
      "기왓장 내외\n",
      "오줌싸개 지도\n",
      "병아리\n",
      "조개껍질\n",
      "겨울\n",
      "트루게네프의 언덕\n",
      "달을 쏘다\n",
      "별똥 떨어진 데\n",
      "화원에 꽃이 핀다\n",
      "종시\n"
     ]
    }
   ],
   "source": [
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "writedP = soup.select('#mw-content-text > div.mw-parser-output > ul > li a')\n",
    "# print(writedP)\n",
    "for i in writedP:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연근\n",
      "아보카도\n",
      "<li class=\"black\" data-lo=\"us\">아보카도</li>\n",
      "[<li class=\"black\" data-lo=\"us\">아보카도</li>]\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"fruits-vegetables.html\", encoding=\"utf-8\")\n",
    "\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "print( soup.select_one('li:nth-of-type(5)').string)\n",
    "print(soup.select_one(\"#ve-list > li:nth-of-type(4)\").string)\n",
    "print( soup.select(\"#ve-list > li[data-lo='us']\")[1])\n",
    "print( soup.select(\"#ve-list > li.black[data-lo='us']\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도\n",
      "아보카도\n"
     ]
    }
   ],
   "source": [
    "# 검색 조건 미리 설정\n",
    "cond ={'data-lo' : 'us', 'class' : 'black'}\n",
    "print( soup.find('li', cond).string)\n",
    "print( soup.find(id='ve-list').find('li', cond).string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoge.html\n",
      "https://example.com/fuga\n",
      "https://example.com/foo\n",
      "https://example.com/aaa\n",
      "==========\n",
      "https://example.com/fuga\n",
      "https://example.com/foo\n",
      "https://example.com/aaa\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "html = \"\"\"\n",
    "    <ul>\n",
    "        <li><a href=\"hoge.html\">hoge</a></li>\n",
    "        <li><a href=\"https://example.com/fuga\">fuga*</a></li>\n",
    "        <li><a href=\"https://example.com/foo\">foo*</a></li>\n",
    "        <li><a href=\"https://example.com/aaa\">aaa</a></li>\n",
    "    </ul>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html , 'html.parser')\n",
    "\n",
    "lis = soup.find_all(\"a\")\n",
    "for e in lis:\n",
    "    print(e.attrs['href'])\n",
    "print(\"=\"*10)\n",
    "lis2 = soup.find_all(href=re.compile(r'^https://'))\n",
    "for i in lis2:\n",
    "    print(i.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/07/20 16:35:43\n",
      "b'2022/07/20 16:35:43'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"http://api.aoikujira.com/time/get.php\")\n",
    "\n",
    "# 텍스트형식으로 출력\n",
    "text =r.text\n",
    "print(text)\n",
    "\n",
    "#바이너리 형식으로 \n",
    "bin = r.content\n",
    "print(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금속노조 4000명 총파업 돌입..원청 사측 3000명 맞불집회에 긴장 고조\n",
      "\"공공기관 단체교섭 보장해야\"..한국노총, ILO에 정부 제소\n",
      "故노회찬 4주기 토론회..\"정치혐오 시대, 노회찬 말 그리워\"\n",
      "역대급 폭염에 화마까지 덮친 유럽..사망자까지 속출[더뉴스]\n",
      "'코로나19 청정국은 없다'..미크로네시아, 확진자 무더기 발견\n",
      "정부가 청년의 '빚투'까지 탕감하려 하나?[이슈체크K]\n",
      "영국대사 내쫓고 러시아와 밀월..미얀마 군부, 장기 집권 터 닦기\n",
      "IDC \"세계 반도체 부족 진행형..IT 소비지출 침체 신호\"\n",
      "국가교육위원회, 내일부터 법 시행..민주당, 위원 추천 절차 돌입\n",
      "9월에 세종 5생활권 외곽도로 완공..3생활권 BRT환승센터 착공\n",
      "고물가에 국민 4명중 1명 \"제주보다 동해\".. 평균 휴가비용은 95만원\n",
      "세계 50개 교향악단 연주자들의 '고잉 홈' 음악 향연\n",
      "황영호 충북도의장 \"도민이 도의회의 주인\"[인터뷰]\n",
      "성추행 피해 학생 외면하지 않은 대가.. 끝나지 않는 '10년 소송전'[플랫]\n",
      "與 혁신위, 당원 이어 국민 목소리 듣는다..\"개선점 의견 기대\"\n",
      "돌봄센터·장애노숙인시설 등 1.6만곳에 7~8월 전기요금 80% 할인\n",
      "日 시민단체 , 아베 전 총리 '국장' 반대..\"사상과 양심의 자유 위배\"\n",
      "한공노협, '노동3권 위반' 국제노동기구에 정부 제소\n",
      "'공식 의정활동 5분' 경기도의원들, 이달 의정비 554만원씩 수령\n",
      "고물가·코로나 재유행에..인천 소매유통 체감경기 급랭\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\"https://news.daum.net/\")\n",
    "html = req.text\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "newsTitle = soup.select('ul.list_newsissue > li > div.item_issue > div.cont_thumb > strong.tit_g > a')\n",
    "\n",
    "for i in newsTitle:\n",
    "    print(i.string.strip())\n",
    "print(len(newsTitle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문 바로가기\n",
      "메뉴 바로가기\n",
      "연예\n",
      "스포츠\n",
      "홈\n",
      "사회\n",
      "정치\n",
      "경제\n",
      "국제\n",
      "문화\n",
      "IT\n",
      "연재\n",
      "포토\n",
      "팩트체크\n",
      "금속노조 4000명 총파업 돌입..원청 사측 3000명 맞불집회에 긴장 고조\n",
      "\"공공기관 단체교섭 보장해야\"..한국노총, ILO에 정부 제소\n",
      "故노회찬 4주기 토론회..\"정치혐오 시대, 노회찬 말 그리워\"\n",
      "역대급 폭염에 화마까지 덮친 유럽..사망자까지 속출[더뉴스]\n",
      "'코로나19 청정국은 없다'..미크로네시아, 확진자 무더기 발견\n",
      "정부가 청년의 '빚투'까지 탕감하려 하나?[이슈체크K]\n",
      "영국대사 내쫓고 러시아와 밀월..미얀마 군부, 장기 집권 터 닦기\n",
      "IDC \"세계 반도체 부족 진행형..IT 소비지출 침체 신호\"\n",
      "국가교육위원회, 내일부터 법 시행..민주당, 위원 추천 절차 돌입\n",
      "9월에 세종 5생활권 외곽도로 완공..3생활권 BRT환승센터 착공\n",
      "고물가에 국민 4명중 1명 \"제주보다 동해\".. 평균 휴가비용은 95만원\n",
      "세계 50개 교향악단 연주자들의 '고잉 홈' 음악 향연\n",
      "황영호 충북도의장 \"도민이 도의회의 주인\"[인터뷰]\n",
      "성추행 피해 학생 외면하지 않은 대가.. 끝나지 않는 '10년 소송전'[플랫]\n",
      "與 혁신위, 당원 이어 국민 목소리 듣는다..\"개선점 의견 기대\"\n",
      "돌봄센터·장애노숙인시설 등 1.6만곳에 7~8월 전기요금 80% 할인\n",
      "日 시민단체 , 아베 전 총리 '국장' 반대..\"사상과 양심의 자유 위배\"\n",
      "한공노협, '노동3권 위반' 국제노동기구에 정부 제소\n",
      "'공식 의정활동 5분' 경기도의원들, 이달 의정비 554만원씩 수령\n",
      "고물가·코로나 재유행에..인천 소매유통 체감경기 급랭\n",
      "[이슈체크K] 정부가 청년의 '빚투'까지 탕감하려 하나?\n",
      "[영상] 푸틴, 현존 최대 핵폭격기 '하얀 백조' 띄워 핀란드·스웨덴 위협 [나우,어스]\n",
      "기후변화로 태풍·가뭄 등 자연재해 2000년대에 3536건..50년 전보다 5배 늘어\n",
      "파업 무관심하더니.. 대통령 말에 정부·사측 입장 보도 '우르르' [대우조선해양 하청노조 파업]\n",
      "성추행 피해 학생 외면하지 않은 대가.. 끝나지 않는 '10년 소송전'[플랫]\n",
      "[취재파일] \"사실 아니다\"라는 시민사회수석..총무비서관실 검찰 수사관 파견, 팩트는?\n",
      "[오마이포토] '세월호참사 기억공간을 지켜주세요'\n",
      "당권 노리는 안철수 \"내일 새 지도체제 입장 밝히겠다\"\n",
      "전체보기\n",
      "뜨거운 열기의 대학입시정보박람회\n",
      "농협유통, '22년 추석 선물세트 사전 예약 할인 행사 진행'\n",
      "일제 강점기 때 끊긴 '창경궁-종묘' 90년 만에 다시 연결\n",
      "목표를 향해\n",
      "더보기\n",
      "더보기\n",
      "뉴스홈\n",
      "사회\n",
      "정치\n",
      "경제\n",
      "국제\n",
      "문화\n",
      "IT\n",
      "포토\n",
      "언론사별 뉴스\n",
      "배열이력\n",
      "전체뉴스\n",
      "연재\n",
      "팩트체크\n",
      "다음뉴스 소개\n",
      "공지사항\n",
      "게시물 운영원칙\n",
      "서비스 약관/정책\n",
      "뉴스제휴\n",
      "비즈니스\n",
      "권리침해신고\n",
      "다음뉴스 고객센터\n",
      "24시간 뉴스센터\n",
      "서비스원칙\n",
      "고침기사, 정정・반론・추후보도 모음\n",
      "Kakao Corp.\n"
     ]
    }
   ],
   "source": [
    "links = soup.select('a[href]')\n",
    "for link in links:\n",
    "    try:\n",
    "        print(link.string.strip())\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "금속노조 4000명 총파업 돌입..원청 사측 3000명 맞불집회에 긴장 고조\n",
      "\n",
      "\"공공기관 단체교섭 보장해야\"..한국노총, ILO에 정부 제소\n",
      "\n",
      "故노회찬 4주기 토론회..\"정치혐오 시대, 노회찬 말 그리워\"\n",
      "\n",
      "역대급 폭염에 화마까지 덮친 유럽..사망자까지 속출[더뉴스]\n",
      "\n",
      "'코로나19 청정국은 없다'..미크로네시아, 확진자 무더기 발견\n",
      "\n",
      "정부가 청년의 '빚투'까지 탕감하려 하나?[이슈체크K]\n",
      "\n",
      "영국대사 내쫓고 러시아와 밀월..미얀마 군부, 장기 집권 터 닦기\n",
      "\n",
      "IDC \"세계 반도체 부족 진행형..IT 소비지출 침체 신호\"\n",
      "\n",
      "국가교육위원회, 내일부터 법 시행..민주당, 위원 추천 절차 돌입\n",
      "\n",
      "9월에 세종 5생활권 외곽도로 완공..3생활권 BRT환승센터 착공\n",
      "\n",
      "고물가에 국민 4명중 1명 \"제주보다 동해\".. 평균 휴가비용은 95만원\n",
      "\n",
      "세계 50개 교향악단 연주자들의 '고잉 홈' 음악 향연\n",
      "\n",
      "황영호 충북도의장 \"도민이 도의회의 주인\"[인터뷰]\n",
      "\n",
      "성추행 피해 학생 외면하지 않은 대가.. 끝나지 않는 '10년 소송전'[플랫]\n",
      "\n",
      "與 혁신위, 당원 이어 국민 목소리 듣는다..\"개선점 의견 기대\"\n",
      "\n",
      "돌봄센터·장애노숙인시설 등 1.6만곳에 7~8월 전기요금 80% 할인\n",
      "\n",
      "日 시민단체 , 아베 전 총리 '국장' 반대..\"사상과 양심의 자유 위배\"\n",
      "\n",
      "한공노협, '노동3권 위반' 국제노동기구에 정부 제소\n",
      "\n",
      "'공식 의정활동 5분' 경기도의원들, 이달 의정비 554만원씩 수령\n",
      "\n",
      "고물가·코로나 재유행에..인천 소매유통 체감경기 급랭\n",
      "\n",
      "[이슈체크K] 정부가 청년의 '빚투'까지 탕감하려 하나?\n",
      "\n",
      "[영상] 푸틴, 현존 최대 핵폭격기 '하얀 백조' 띄워 핀란드·스웨덴 위협 [나우,어스]\n",
      "\n",
      "기후변화로 태풍·가뭄 등 자연재해 2000년대에 3536건..50년 전보다 5배 늘어\n",
      "\n",
      "파업 무관심하더니.. 대통령 말에 정부·사측 입장 보도 '우르르' [대우조선해양 하청노조 파업]\n",
      "\n",
      "성추행 피해 학생 외면하지 않은 대가.. 끝나지 않는 '10년 소송전'[플랫]\n",
      "\n",
      "[취재파일] \"사실 아니다\"라는 시민사회수석..총무비서관실 검찰 수사관 파견, 팩트는?\n",
      "\n",
      "[오마이포토] '세월호참사 기억공간을 지켜주세요'\n",
      "\n",
      "당권 노리는 안철수 \"내일 새 지도체제 입장 밝히겠다\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for t in links:\n",
    "    if re.search(r'https://v.\\w+',t['href']):\n",
    "        print(t.get_text().strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul>\n",
      "<li><a class=\"on\" data-type=\"DOMESTIC\" href=\"javascript:void(0)\" title=\"국내 지수\">국내 지수</a></li>\n",
      "<li><a data-type=\"USA\" href=\"javascript:void(0)\" title=\"미국 지수\">미국 지수</a></li>\n",
      "<li><a data-type=\"ASIA\" href=\"javascript:void(0)\" title=\"아시아 지수\">아시아 지수</a></li>\n",
      "<li><a data-type=\"EUROPE\" href=\"javascript:void(0)\" title=\"유럽 지수\">유럽 지수</a></li>\n",
      "</ul>\n",
      "\n",
      "\n",
      "국내 지수\n",
      "\n",
      "\n",
      "미국 지수\n",
      "\n",
      "\n",
      "아시아 지수\n",
      "\n",
      "\n",
      "유럽 지수\n",
      "\n",
      "\n",
      "[<a class=\"on\" data-type=\"DOMESTIC\" href=\"javascript:void(0)\" title=\"국내 지수\">국내 지수</a>, <a data-type=\"USA\" href=\"javascript:void(0)\" title=\"미국 지수\">미국 지수</a>, <a data-type=\"ASIA\" href=\"javascript:void(0)\" title=\"아시아 지수\">아시아 지수</a>, <a data-type=\"EUROPE\" href=\"javascript:void(0)\" title=\"유럽 지수\">유럽 지수</a>]\n",
      "['국내 지수', '미국 지수', '아시아 지수', '유럽 지수']\n"
     ]
    }
   ],
   "source": [
    "req = requests.get('https://finance.daum.net/')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "mainStock = soup.find('div',class_=\"stockTab\")\n",
    "print(mainStock.ul)\n",
    "\n",
    "for i in mainStock.ul:\n",
    "    print(i.string)\n",
    "    \n",
    "lis = soup.select(\"#boxIndexTabs > ul > li a\")\n",
    "print(lis)\n",
    "datas = []\n",
    "for i in lis:\n",
    "    datas.append(i.get_text())\n",
    "print(datas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "18\n",
      "\n",
      "\n",
      "20\n",
      "\n",
      "\n",
      "22\n",
      "\n",
      "\n",
      "38\n",
      "\n",
      "\n",
      "44\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\"https://dhlottery.co.kr/gameResult.do?method=byWin\")\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "winNum = soup.find('div', class_='num win')\n",
    "# print(winNum.p)\n",
    "\n",
    "data = []\n",
    "for p in winNum.p:\n",
    "    print(p.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t18\t20\t22\t38\t44\t10\t"
     ]
    }
   ],
   "source": [
    "    \n",
    "ballNum = soup.find_all('span', class_='ball_645')\n",
    "for i in ballNum:\n",
    "    print(i.get_text(), end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr class=\"down\">\n",
      "<th scope=\"row\"><em>1.</em><a href=\"/item/main.naver?code=005930\" onclick=\"clickcr(this, 'boa.list', '005930', '1', event);\">삼성전자</a></th>\n",
      "<td>60,500</td>\n",
      "<td> <img alt=\"하락\" height=\"6\" src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_down.gif\" style=\"margin-right:4px;\" width=\"7\"/><span class=\"tah p11 nv01\"> 400 </span> </td>\n",
      "</tr>, <tr class=\"up\">\n",
      "<th scope=\"row\"><em>2.</em><a href=\"/item/main.naver?code=091090\" onclick=\"clickcr(this, 'boa.list', '091090', '2', event);\">세원이앤씨</a></th>\n",
      "<td>867</td>\n",
      "<td> <img alt=\"상승\" height=\"6\" src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" style=\"margin-right:4px;\" width=\"7\"/><span class=\"tah p11 red02\"> 66 </span> </td>\n",
      "</tr>, <tr class=\"up\">\n",
      "<th scope=\"row\"><em>3.</em><a href=\"/item/main.naver?code=035720\" onclick=\"clickcr(this, 'boa.list', '035720', '3', event);\">카카오</a></th>\n",
      "<td>73,400</td>\n",
      "<td> <img alt=\"상승\" height=\"6\" src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" style=\"margin-right:4px;\" width=\"7\"/><span class=\"tah p11 red02\"> 600 </span> </td>\n",
      "</tr>, <tr class=\"up\">\n",
      "<th scope=\"row\"><em>4.</em><a href=\"/item/main.naver?code=000660\" onclick=\"clickcr(this, 'boa.list', '000660', '4', event);\">SK하이닉스</a></th>\n",
      "<td>102,000</td>\n",
      "<td> <img alt=\"상승\" height=\"6\" src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" style=\"margin-right:4px;\" width=\"7\"/><span class=\"tah p11 red02\"> 2,000 </span> </td>\n",
      "</tr>, <tr class=\"up\">\n",
      "<th scope=\"row\"><em>5.</em><a href=\"/item/main.naver?code=005380\" onclick=\"clickcr(this, 'boa.list', '005380', '5', event);\">현대차</a></th>\n",
      "<td>189,000</td>\n",
      "<td> <img alt=\"상승\" height=\"6\" src=\"https://ssl.pstatic.net/imgstock/images/images4/ico_up.gif\" style=\"margin-right:4px;\" width=\"7\"/><span class=\"tah p11 red02\"> 500 </span> </td>\n",
      "</tr>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Workbook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\PythonProjects\\d03.ipynb 셀 27\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PythonProjects/d03.ipynb#ch0000032?line=22'>23</a>\u001b[0m df \u001b[39m=\u001b[39m  pd\u001b[39m.\u001b[39mDataFrame(data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PythonProjects/d03.ipynb#ch0000032?line=23'>24</a>\u001b[0m                    columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m종목\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m가격\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m방향\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m변동\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PythonProjects/d03.ipynb#ch0000032?line=25'>26</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m./csv/result.csv\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8-sig\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/PythonProjects/d03.ipynb#ch0000032?line=27'>28</a>\u001b[0m write_wb \u001b[39m=\u001b[39m Workbook()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PythonProjects/d03.ipynb#ch0000032?line=28'>29</a>\u001b[0m write_ws \u001b[39m=\u001b[39m write_wb\u001b[39m.\u001b[39mcreate_sheet(\u001b[39m'\u001b[39m\u001b[39m결과\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Workbook' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "req = requests.get('https://finance.naver.com/')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "popularStock = soup.select_one('#container > div.aside > div > div.aside_area.aside_popular > table > tbody')\n",
    "trs = popularStock.select('tr')\n",
    "print(trs)\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in trs:\n",
    "    name = i.select_one('th > a').get_text()\n",
    "    cur_price = i.select_one('td').get_text()\n",
    "    # ch_direction = i['class'][0]\n",
    "    ch_direction = i.select_one('td > img')['alt']\n",
    "    ch_price = i.select_one('td > span').get_text().strip()\n",
    "    data.append([name, cur_price, ch_direction, ch_price])\n",
    "\n",
    "\n",
    "df =  pd.DataFrame(data,\n",
    "                   columns=['종목', '가격', \"방향\", '변동'])\n",
    "\n",
    "df.to_csv('./csv/result.csv', encoding='utf-8-sig')\n",
    "\n",
    "write_wb = Workbook()\n",
    "write_ws = write_wb.create_sheet('결과')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id: YK9LIw42c4ql85gJ3OZk\n",
    "# key : jRaHLgtFgo\n",
    "import urllib.request\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "clientId = 'YK9LIw42c4ql85gJ3OZk'\n",
    "clientSecret = 'jRaHLgtFgo'\n",
    "\n",
    "def getRequestUrl(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", clientId)\n",
    "    req.add_header(\"X-Naver-Client-Secret\", clientSecret)\n",
    "  \n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print(f'[{datetime.datetime.now()}] Url request Success')\n",
    "            return response.read().decode('utf-8')\n",
    "    except:\n",
    "        print('error')\n",
    "        \n",
    "    return None\n",
    "\n",
    "def getNaverSearch(node, srcText, start, display):\n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = '/news.json'\n",
    "    srcText = urllib.parse.quote(srcText)\n",
    "    parameters = f'?query={srcText}&start={start}&display={display}'\n",
    "    url = base + node + parameters\n",
    "    print(url)\n",
    "    reponseDecode = getRequestUrl(url)\n",
    "    if reponseDecode == None:\n",
    "        return None\n",
    "    else:\n",
    "        # json 문자열을 Python 객체로 \n",
    "        return json.loads(reponseDecode)\n",
    "\n",
    "def getPostData(post, jsonResult, cnt):\n",
    "    title = post['title']\n",
    "    description = post['description']\n",
    "    originallink = post['originallink']\n",
    "    link = post['link']\n",
    "    pubDate = post['pubDate']\n",
    "    jsonResult.append({'cnt': cnt,\n",
    "                       'title': title,\n",
    "                       'description': description,\n",
    "                       'originallink': originallink,\n",
    "                       'link': link,\n",
    "                       'pubDate': pubDate})\n",
    "\n",
    "node = 'news'\n",
    "srcText = '선거'\n",
    "cnt = 0\n",
    "jsonResult =[]\n",
    "\n",
    "jsonResponse = getNaverSearch(node, srcText, 1, 100) \n",
    "total = jsonResponse['total']\n",
    "print(total)\n",
    "\n",
    "while( (jsonResponse != None) and (jsonResponse['display']  != 0 )):\n",
    "    for post in jsonResponse['items']:\n",
    "        cnt += 1\n",
    "        getPostData(post, jsonResult, cnt)\n",
    "        \n",
    "    start = jsonResponse['start']+ jsonResponse['display']\n",
    "    jsonResponse = getNaverSearch(node, srcText, start, 10)\n",
    "    \n",
    "with open(f'./json/{srcText}_naver_{node}.json', 'w', encoding='utf-8-sig') as outputFile:\n",
    "    jsonFile = json.dumps(jsonResult, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "    outputFile.write(jsonFile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_13460\\3138949881.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "path = 'D:\\\\program_files\\\\chromedriver_win32\\\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.implicitly_wait(2)\n",
    "driver.get('https://www.youtube.com/c/paikscuisine/videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21881\n",
      "21881\n",
      "21881\n"
     ]
    }
   ],
   "source": [
    "# ActionChains 를 사용하기 위해서.\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "allVideos = driver.find_elements(By.ID, 'dismissible')\n",
    "body_tag = driver.find_element(By.TAG_NAME, 'body')\n",
    "\n",
    "while True:\n",
    "    body_tag.send_keys(Keys.END)\n",
    "    last_height = driver.execute_script('return document.documentElement.scrollHeight')\n",
    "    print(lastHeight)\n",
    "    \n",
    "    for i in range(10):\n",
    "        body_tag.send_keys(Keys.END)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "    new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # id가 something 인 element 를 찾음\n",
    "# some_tag = driver.find_element(By.ID,'show-more-button')\n",
    "\n",
    "# # somthing element 까지 스크롤\n",
    "# action = ActionChains(driver)\n",
    "# action.move_to_element(some_tag).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "\n",
    "dbURL = '127.0.0.1'\n",
    "dbPort = 3306\n",
    "dbUser = 'root'\n",
    "dbPass = 'root'\n",
    "\n",
    "conn = pymysql.connect(host = dbURL, \n",
    "                       port = dbPort, \n",
    "                       user = dbUser, \n",
    "                       passwd = dbPass,\n",
    "                       db = 'bigdb',\n",
    "                       charset = 'utf8',\n",
    "                       use_unicode=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2022-08-01 00:00',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "insert_weather = 'insert into forecast (city, tmef, wf, tmn, tmx) values (%s,%s,%s,%s,%s)'\n",
    "\n",
    "\n",
    "req = requests.get('http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp?stnId2=108')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "weather = dict()\n",
    "\n",
    "select_data = \"select tmef from forecast order by tmef desc limit 1\"\n",
    "cur =conn.cursor()\n",
    "cur.execute(select_data)\n",
    "lastdata = cur.fetchone()\n",
    "print(lastdata)\n",
    "\n",
    "for i in soup.find_all('location'):\n",
    "    weather[i.find('city').text] = []\n",
    "\n",
    "    for j in i.find_all('data'):\n",
    "        temp = []\n",
    "        if (lastdata is None) or (j.find('tmef').text > str(lastdata[0]) )  :\n",
    "            temp.append(j.find('tmef').text)\n",
    "            temp.append(j.find('wf').text)\n",
    "            temp.append(j.find('tmn').text)\n",
    "            temp.append(j.find('tmx').text)\n",
    "            weather[i.find('city').text].append(temp)\n",
    "        \n",
    "\n",
    "for i in weather:\n",
    "    for j in weather[i]:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(insert_weather, (i, j[0],j[1], j[2], j[3]))\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('31', '24')\n"
     ]
    }
   ],
   "source": [
    "select_busan = \"select max(tmx), min(tmn) from forecast where city = '부산' order by tmef desc\"\n",
    "cur = conn.cursor()\n",
    "cur.execute(select_busan)\n",
    "busan = cur.fetchone()\n",
    "print(busan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
